{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold , KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility setup\n",
    "RANDOM_SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/mingu/Desktop/CODING/2024_1 Machine Learning/Kaggle Project 2/DATASET/train.csv\").drop(\"~\", axis = 1) #경로지정\n",
    "test = pd.read_csv(\"/Users/mingu/Desktop/CODING/2024_1 Machine Learning/Kaggle Project 2/DATASET/test.csv\").drop(\"No\", axis = 1)\n",
    "sample_sub = pd.read_csv(\"/Users/mingu/Desktop/CODING/2024_1 Machine Learning/Kaggle Project 2/DATASET/submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingu/miniforge3/envs/ai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import json\n",
    "from sklearn.utils import check_array\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "\n",
    "class TorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Format for numpy array\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2D array\n",
    "        The input matrix\n",
    "    y : 2D array\n",
    "        The one-hot encoded target\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.x[index], self.y[index]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "class PredictDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Format for numpy array\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 2D array\n",
    "        The input matrix\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        return x\n",
    "\n",
    "\n",
    "def create_sampler(weights, y_train):\n",
    "    \"\"\"\n",
    "    This creates a sampler from the given weights\n",
    "    Parameters\n",
    "    ----------\n",
    "    weights : either 0, 1, dict or iterable\n",
    "        if 0 (default) : no weights will be applied\n",
    "        if 1 : classification only, will balanced class with inverse frequency\n",
    "        if dict : keys are corresponding class values are sample weights\n",
    "        if iterable : list or np array must be of length equal to nb elements\n",
    "                      in the training set\n",
    "    y_train : np.array\n",
    "        Training targets\n",
    "    \"\"\"\n",
    "    if isinstance(weights, int):\n",
    "        if weights == 0:\n",
    "            need_shuffle = True\n",
    "            sampler = None\n",
    "        elif weights == 1:\n",
    "            need_shuffle = False\n",
    "            class_sample_count = np.array(\n",
    "                [len(np.where(y_train == t)[0]) for t in np.unique(y_train)]\n",
    "            )\n",
    "\n",
    "            weights = 1.0 / class_sample_count\n",
    "\n",
    "            samples_weight = np.array([weights[t] for t in y_train])\n",
    "\n",
    "            samples_weight = torch.from_numpy(samples_weight)\n",
    "            samples_weight = samples_weight.double()\n",
    "            sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "        else:\n",
    "            raise ValueError(\"Weights should be either 0, 1, dictionnary or list.\")\n",
    "    elif isinstance(weights, dict):\n",
    "        # custom weights per class\n",
    "        need_shuffle = False\n",
    "        samples_weight = np.array([weights[t] for t in y_train])\n",
    "        sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    else:\n",
    "        # custom weights\n",
    "        if len(weights) != len(y_train):\n",
    "            raise ValueError(\"Custom weights should match number of train samples.\")\n",
    "        need_shuffle = False\n",
    "        samples_weight = np.array(weights)\n",
    "        sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    return need_shuffle, sampler\n",
    "\n",
    "\n",
    "def create_dataloaders(\n",
    "    X_train, y_train, eval_set, weights, batch_size, num_workers, drop_last, pin_memory\n",
    "):\n",
    "    \"\"\"\n",
    "    Create dataloaders with or without subsampling depending on weights and balanced.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : np.ndarray\n",
    "        Training data\n",
    "    y_train : np.array\n",
    "        Mapped Training targets\n",
    "    eval_set : list of tuple\n",
    "        List of eval tuple set (X, y)\n",
    "    weights : either 0, 1, dict or iterable\n",
    "        if 0 (default) : no weights will be applied\n",
    "        if 1 : classification only, will balanced class with inverse frequency\n",
    "        if dict : keys are corresponding class values are sample weights\n",
    "        if iterable : list or np array must be of length equal to nb elements\n",
    "                      in the training set\n",
    "    batch_size : int\n",
    "        how many samples per batch to load\n",
    "    num_workers : int\n",
    "        how many subprocesses to use for data loading. 0 means that the data\n",
    "        will be loaded in the main process\n",
    "    drop_last : bool\n",
    "        set to True to drop the last incomplete batch, if the dataset size is not\n",
    "        divisible by the batch size. If False and the size of dataset is not\n",
    "        divisible by the batch size, then the last batch will be smaller\n",
    "    pin_memory : bool\n",
    "        Whether to pin GPU memory during training\n",
    "    Returns\n",
    "    -------\n",
    "    train_dataloader, valid_dataloader : torch.DataLoader, torch.DataLoader\n",
    "        Training and validation dataloaders\n",
    "    \"\"\"\n",
    "    need_shuffle, sampler = create_sampler(weights, y_train)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        TorchDataset(X_train.astype(np.float32), y_train),\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler,\n",
    "        shuffle=need_shuffle,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=drop_last,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    valid_dataloaders = []\n",
    "    for X, y in eval_set:\n",
    "        valid_dataloaders.append(\n",
    "            DataLoader(\n",
    "                TorchDataset(X.astype(np.float32), y),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=pin_memory,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return train_dataloader, valid_dataloaders\n",
    "\n",
    "\n",
    "def create_explain_matrix(input_dim, cat_emb_dim, cat_idxs, post_embed_dim):\n",
    "    \"\"\"\n",
    "    This is a computational trick.\n",
    "    In order to rapidly sum importances from same embeddings\n",
    "    to the initial index.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dim : int\n",
    "        Initial input dim\n",
    "    cat_emb_dim : int or list of int\n",
    "        if int : size of embedding for all categorical feature\n",
    "        if list of int : size of embedding for each categorical feature\n",
    "    cat_idxs : list of int\n",
    "        Initial position of categorical features\n",
    "    post_embed_dim : int\n",
    "        Post embedding inputs dimension\n",
    "    Returns\n",
    "    -------\n",
    "    reducing_matrix : np.array\n",
    "        Matrix of dim (post_embed_dim, input_dim)  to performe reduce\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(cat_emb_dim, int):\n",
    "        all_emb_impact = [cat_emb_dim - 1] * len(cat_idxs)\n",
    "    else:\n",
    "        all_emb_impact = [emb_dim - 1 for emb_dim in cat_emb_dim]\n",
    "\n",
    "    acc_emb = 0\n",
    "    nb_emb = 0\n",
    "    indices_trick = []\n",
    "    for i in range(input_dim):\n",
    "        if i not in cat_idxs:\n",
    "            indices_trick.append([i + acc_emb])\n",
    "        else:\n",
    "            indices_trick.append(\n",
    "                range(i + acc_emb, i + acc_emb + all_emb_impact[nb_emb] + 1)\n",
    "            )\n",
    "            acc_emb += all_emb_impact[nb_emb]\n",
    "            nb_emb += 1\n",
    "\n",
    "    reducing_matrix = np.zeros((post_embed_dim, input_dim))\n",
    "    for i, cols in enumerate(indices_trick):\n",
    "        reducing_matrix[cols, i] = 1\n",
    "\n",
    "    return scipy.sparse.csc_matrix(reducing_matrix)\n",
    "\n",
    "\n",
    "def filter_weights(weights):\n",
    "    \"\"\"\n",
    "    This function makes sure that weights are in correct format for\n",
    "    regression and multitask TabNet\n",
    "    Parameters\n",
    "    ----------\n",
    "    weights : int, dict or list\n",
    "        Initial weights parameters given by user\n",
    "    Returns\n",
    "    -------\n",
    "    None : This function will only throw an error if format is wrong\n",
    "    \"\"\"\n",
    "    err_msg = \"\"\"Please provide a list or np.array of weights for \"\"\"\n",
    "    err_msg += \"\"\"regression, multitask or pretraining: \"\"\"\n",
    "    if isinstance(weights, int):\n",
    "        if weights == 1:\n",
    "            raise ValueError(err_msg + \"1 given.\")\n",
    "    if isinstance(weights, dict):\n",
    "        raise ValueError(err_msg + \"Dict given.\")\n",
    "    return\n",
    "\n",
    "\n",
    "def validate_eval_set(eval_set, eval_name, X_train, y_train):\n",
    "    \"\"\"Check if the shapes of eval_set are compatible with (X_train, y_train).\n",
    "    Parameters\n",
    "    ----------\n",
    "    eval_set : list of tuple\n",
    "        List of eval tuple set (X, y).\n",
    "        The last one is used for early stopping\n",
    "    eval_name : list of str\n",
    "        List of eval set names.\n",
    "    X_train : np.ndarray\n",
    "        Train owned products\n",
    "    y_train : np.array\n",
    "        Train targeted products\n",
    "    Returns\n",
    "    -------\n",
    "    eval_names : list of str\n",
    "        Validated list of eval_names.\n",
    "    eval_set : list of tuple\n",
    "        Validated list of eval_set.\n",
    "    \"\"\"\n",
    "    eval_name = eval_name or [f\"val_{i}\" for i in range(len(eval_set))]\n",
    "\n",
    "    assert len(eval_set) == len(\n",
    "        eval_name\n",
    "    ), \"eval_set and eval_name have not the same length\"\n",
    "    if len(eval_set) > 0:\n",
    "        assert all(\n",
    "            len(elem) == 2 for elem in eval_set\n",
    "        ), \"Each tuple of eval_set need to have two elements\"\n",
    "    for name, (X, y) in zip(eval_name, eval_set):\n",
    "        check_input(X)\n",
    "        msg = (\n",
    "            f\"Dimension mismatch between X_{name} \"\n",
    "            + f\"{X.shape} and X_train {X_train.shape}\"\n",
    "        )\n",
    "        assert len(X.shape) == len(X_train.shape), msg\n",
    "\n",
    "        msg = (\n",
    "            f\"Dimension mismatch between y_{name} \"\n",
    "            + f\"{y.shape} and y_train {y_train.shape}\"\n",
    "        )\n",
    "        assert len(y.shape) == len(y_train.shape), msg\n",
    "\n",
    "        msg = (\n",
    "            f\"Number of columns is different between X_{name} \"\n",
    "            + f\"({X.shape[1]}) and X_train ({X_train.shape[1]})\"\n",
    "        )\n",
    "        assert X.shape[1] == X_train.shape[1], msg\n",
    "\n",
    "        if len(y_train.shape) == 2:\n",
    "            msg = (\n",
    "                f\"Number of columns is different between y_{name} \"\n",
    "                + f\"({y.shape[1]}) and y_train ({y_train.shape[1]})\"\n",
    "            )\n",
    "            assert y.shape[1] == y_train.shape[1], msg\n",
    "        msg = (\n",
    "            f\"You need the same number of rows between X_{name} \"\n",
    "            + f\"({X.shape[0]}) and y_{name} ({y.shape[0]})\"\n",
    "        )\n",
    "        assert X.shape[0] == y.shape[0], msg\n",
    "\n",
    "    return eval_name, eval_set\n",
    "\n",
    "\n",
    "def define_device(device_name):\n",
    "    \"\"\"\n",
    "    Define the device to use during training and inference.\n",
    "    If auto it will detect automatically whether to use cuda or cpu\n",
    "    Parameters\n",
    "    ----------\n",
    "    device_name : str\n",
    "        Either \"auto\", \"cpu\" or \"cuda\"\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Either \"cpu\" or \"cuda\"\n",
    "    \"\"\"\n",
    "    if device_name == \"auto\":\n",
    "        if torch.cuda.is_available():\n",
    "            return \"cuda\"\n",
    "        else:\n",
    "            return \"cpu\"\n",
    "    elif device_name == \"cuda\" and not torch.cuda.is_available():\n",
    "        return \"cpu\"\n",
    "    else:\n",
    "        return device_name\n",
    "\n",
    "\n",
    "class ComplexEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.int64):\n",
    "            return int(obj)\n",
    "        # Let the base class default method raise the TypeError\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "def check_input(X):\n",
    "    \"\"\"\n",
    "    Raise a clear error if X is a pandas dataframe\n",
    "    and check array according to scikit rules\n",
    "    \"\"\"\n",
    "    if isinstance(X, (pd.DataFrame, pd.Series)):\n",
    "        err_message = \"Pandas DataFrame are not supported: apply X.values when calling fit\"\n",
    "        raise TypeError(err_message)\n",
    "    check_array(X)\n",
    "\n",
    "\n",
    "def check_warm_start(warm_start, from_unsupervised):\n",
    "    \"\"\"\n",
    "    Gives a warning about ambiguous usage of the two parameters.\n",
    "    \"\"\"\n",
    "    if warm_start and from_unsupervised is not None:\n",
    "        warn_msg = \"warm_start=True and from_unsupervised != None: \"\n",
    "        warn_msg = \"warm_start will be ignore, training will start from unsupervised weights\"\n",
    "        warnings.warn(warn_msg)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Any, Dict\n",
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "from abc import abstractmethod\n",
    "from pytorch_tabnet import tab_network\n",
    "from pytorch_tabnet.callbacks import (\n",
    "    CallbackContainer,\n",
    "    History,\n",
    "    EarlyStopping,\n",
    "    LRSchedulerCallback,\n",
    ")\n",
    "from pytorch_tabnet.metrics import MetricContainer, check_metrics\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import io\n",
    "import json\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import zipfile\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TabModel(BaseEstimator):\n",
    "    \"\"\" Class for TabNet model.\"\"\"\n",
    "\n",
    "    n_d: int = 100\n",
    "    n_a: int = 100\n",
    "    n_steps: int = 3\n",
    "    gamma: float = 0.5\n",
    "    cat_idxs: List[int] = field(default_factory=list)\n",
    "    cat_dims: List[int] = field(default_factory=list)\n",
    "    cat_emb_dim: int = 1\n",
    "    n_independent: int = 5\n",
    "    n_shared: int = 5\n",
    "    epsilon: float = 1e-15\n",
    "    momentum: float = 0.02\n",
    "    lambda_sparse: float = 1e-3\n",
    "    seed: int = 0\n",
    "    clip_value: int = 1\n",
    "    verbose: int = 1\n",
    "    optimizer_fn: Any = torch.optim.Adam\n",
    "    optimizer_params: Dict = field(default_factory=lambda: dict(lr=2e-2))\n",
    "    scheduler_fn: Any = None\n",
    "    scheduler_params: Dict = field(default_factory=dict)\n",
    "    mask_type: str = \"entmax\"\n",
    "    input_dim: int = None\n",
    "    output_dim: int = None\n",
    "    device_name: str = \"auto\"\n",
    "    n_shared_decoder: int = 1\n",
    "    n_indep_decoder: int = 1\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.virtual_batch_size = 128\n",
    "        torch.manual_seed(self.seed)\n",
    "        # Defining device\n",
    "        self.device = torch.device(define_device(self.device_name))\n",
    "        if self.verbose != 0:\n",
    "            warnings.warn(f\"Device used : {self.device}\")\n",
    "\n",
    "        # create deep copies of mutable parameters\n",
    "        self.optimizer_fn = copy.deepcopy(self.optimizer_fn)\n",
    "        self.scheduler_fn = copy.deepcopy(self.scheduler_fn)\n",
    "\n",
    "    def __update__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Updates parameters.\n",
    "        If does not already exists, creates it.\n",
    "        Otherwise overwrite with warnings.\n",
    "        \"\"\"\n",
    "        update_list = [\n",
    "            \"cat_dims\",\n",
    "            \"cat_emb_dim\",\n",
    "            \"cat_idxs\",\n",
    "            \"input_dim\",\n",
    "            \"mask_type\",\n",
    "            \"n_a\",\n",
    "            \"n_d\",\n",
    "            \"n_independent\",\n",
    "            \"n_shared\",\n",
    "            \"n_steps\",\n",
    "        ]\n",
    "        for var_name, value in kwargs.items():\n",
    "            if var_name in update_list:\n",
    "                try:\n",
    "                    exec(f\"global previous_val; previous_val = self.{var_name}\")\n",
    "                    if previous_val != value:  # noqa\n",
    "                        wrn_msg = f\"Pretraining: {var_name} changed from {previous_val} to {value}\"  # noqa\n",
    "                        warnings.warn(wrn_msg)\n",
    "                        exec(f\"self.{var_name} = value\")\n",
    "                except AttributeError:\n",
    "                    exec(f\"self.{var_name} = value\")\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=None,\n",
    "        eval_name=None,\n",
    "        eval_metric=None,\n",
    "        loss_fn=None,\n",
    "        weights=0,\n",
    "        max_epochs=100,\n",
    "        patience=10,\n",
    "        batch_size=1024,\n",
    "        virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        callbacks=None,\n",
    "        pin_memory=True,\n",
    "        from_unsupervised=None,\n",
    "        warm_start=False,\n",
    "        augmentations=None,\n",
    "    ):\n",
    "        \"\"\"Train a neural network stored in self.network\n",
    "        Using train_dataloader for training data and\n",
    "        valid_dataloader for validation.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray\n",
    "            Train set\n",
    "        y_train : np.array\n",
    "            Train targets\n",
    "        eval_set : list of tuple\n",
    "            List of eval tuple set (X, y).\n",
    "            The last one is used for early stopping\n",
    "        eval_name : list of str\n",
    "            List of eval set names.\n",
    "        eval_metric : list of str\n",
    "            List of evaluation metrics.\n",
    "            The last metric is used for early stopping.\n",
    "        loss_fn : callable or None\n",
    "            a PyTorch loss function\n",
    "        weights : bool or dictionnary\n",
    "            0 for no balancing\n",
    "            1 for automated balancing\n",
    "            dict for custom weights per class\n",
    "        max_epochs : int\n",
    "            Maximum number of epochs during training\n",
    "        patience : int\n",
    "            Number of consecutive non improving epoch before early stopping\n",
    "        batch_size : int\n",
    "            Training batch size\n",
    "        virtual_batch_size : int\n",
    "            Batch size for Ghost Batch Normalization (virtual_batch_size < batch_size)\n",
    "        num_workers : int\n",
    "            Number of workers used in torch.utils.data.DataLoader\n",
    "        drop_last : bool\n",
    "            Whether to drop last batch during training\n",
    "        callbacks : list of callback function\n",
    "            List of custom callbacks\n",
    "        pin_memory: bool\n",
    "            Whether to set pin_memory to True or False during training\n",
    "        from_unsupervised: unsupervised trained model\n",
    "            Use a previously self supervised model as starting weights\n",
    "        warm_start: bool\n",
    "            If True, current model parameters are used to start training\n",
    "        \"\"\"\n",
    "        # update model name\n",
    "\n",
    "        self.max_epochs = max_epochs\n",
    "        self.patience = patience\n",
    "        self.batch_size = batch_size\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.drop_last = drop_last\n",
    "        self.input_dim = X_train.shape[1]\n",
    "        self._stop_training = False\n",
    "        self.pin_memory = pin_memory and (self.device.type != \"cpu\")\n",
    "        self.augmentations = augmentations\n",
    "\n",
    "        if self.augmentations is not None:\n",
    "            # This ensure reproducibility\n",
    "            self.augmentations._set_seed()\n",
    "\n",
    "        eval_set = eval_set if eval_set else []\n",
    "\n",
    "        if loss_fn is None:\n",
    "            self.loss_fn = self._default_loss\n",
    "        else:\n",
    "            self.loss_fn = loss_fn\n",
    "\n",
    "        check_input(X_train)\n",
    "        check_warm_start(warm_start, from_unsupervised)\n",
    "\n",
    "        self.update_fit_params(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set,\n",
    "            weights,\n",
    "        )\n",
    "\n",
    "        # Validate and reformat eval set depending on training data\n",
    "        eval_names, eval_set = validate_eval_set(eval_set, eval_name, X_train, y_train)\n",
    "\n",
    "        train_dataloader, valid_dataloaders = self._construct_loaders(\n",
    "            X_train, y_train, eval_set\n",
    "        )\n",
    "\n",
    "        if from_unsupervised is not None:\n",
    "            # Update parameters to match self pretraining\n",
    "            self.__update__(**from_unsupervised.get_params())\n",
    "\n",
    "        if not hasattr(self, \"network\") or not warm_start:\n",
    "            # model has never been fitted before of warm_start is False\n",
    "            self._set_network()\n",
    "        self._update_network_params()\n",
    "        self._set_metrics(eval_metric, eval_names)\n",
    "        self._set_optimizer()\n",
    "        self._set_callbacks(callbacks)\n",
    "\n",
    "        if from_unsupervised is not None:\n",
    "            self.load_weights_from_unsupervised(from_unsupervised)\n",
    "            warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
    "        # Call method on_train_begin for all callbacks\n",
    "        self._callback_container.on_train_begin()\n",
    "\n",
    "        # Training loop over epochs\n",
    "        for epoch_idx in range(self.max_epochs):\n",
    "\n",
    "            # Call method on_epoch_begin for all callbacks\n",
    "            self._callback_container.on_epoch_begin(epoch_idx)\n",
    "\n",
    "            self._train_epoch(train_dataloader)\n",
    "\n",
    "            # Apply predict epoch to all eval sets\n",
    "            for eval_name, valid_dataloader in zip(eval_names, valid_dataloaders):\n",
    "                self._predict_epoch(eval_name, valid_dataloader)\n",
    "\n",
    "            # Call method on_epoch_end for all callbacks\n",
    "            self._callback_container.on_epoch_end(\n",
    "                epoch_idx, logs=self.history.epoch_metrics\n",
    "            )\n",
    "\n",
    "            if self._stop_training:\n",
    "                break\n",
    "\n",
    "        # Call method on_train_end for all callbacks\n",
    "        self._callback_container.on_train_end()\n",
    "        self.network.eval()\n",
    "\n",
    "        # compute feature importance once the best model is defined\n",
    "        self.feature_importances_ = self._compute_feature_importances(X_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on a batch (valid)\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : a :tensor: `torch.Tensor`\n",
    "            Input data\n",
    "        Returns\n",
    "        -------\n",
    "        predictions : np.array\n",
    "            Predictions of the regression problem\n",
    "        \"\"\"\n",
    "        self.network.eval()\n",
    "        dataloader = DataLoader(\n",
    "            PredictDataset(X),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        results = []\n",
    "        for batch_nb, data in enumerate(dataloader):\n",
    "            data = data.to(self.device).float()\n",
    "            output, M_loss = self.network(data)\n",
    "            predictions = output.cpu().detach().numpy()\n",
    "            results.append(predictions)\n",
    "        res = np.vstack(results)\n",
    "        return self.predict_func(res)\n",
    "\n",
    "    def explain(self, X, normalize=False):\n",
    "        \"\"\"\n",
    "        Return local explanation\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : tensor: `torch.Tensor`\n",
    "            Input data\n",
    "        normalize : bool (default False)\n",
    "            Wheter to normalize so that sum of features are equal to 1\n",
    "        Returns\n",
    "        -------\n",
    "        M_explain : matrix\n",
    "            Importance per sample, per columns.\n",
    "        masks : matrix\n",
    "            Sparse matrix showing attention masks used by network.\n",
    "        \"\"\"\n",
    "        self.network.eval()\n",
    "\n",
    "        dataloader = DataLoader(\n",
    "            PredictDataset(X),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        res_explain = []\n",
    "\n",
    "        for batch_nb, data in enumerate(dataloader):\n",
    "            data = data.to(self.device).float()\n",
    "\n",
    "            M_explain, masks = self.network.forward_masks(data)\n",
    "            for key, value in masks.items():\n",
    "                masks[key] = csc_matrix.dot(\n",
    "                    value.cpu().detach().numpy(), self.reducing_matrix\n",
    "                )\n",
    "\n",
    "            original_feat_explain = csc_matrix.dot(M_explain.cpu().detach().numpy(),\n",
    "                                                   self.reducing_matrix)\n",
    "            res_explain.append(original_feat_explain)\n",
    "\n",
    "            if batch_nb == 0:\n",
    "                res_masks = masks\n",
    "            else:\n",
    "                for key, value in masks.items():\n",
    "                    res_masks[key] = np.vstack([res_masks[key], value])\n",
    "\n",
    "        res_explain = np.vstack(res_explain)\n",
    "\n",
    "        if normalize:\n",
    "            res_explain /= np.sum(res_explain, axis=1)[:, None]\n",
    "\n",
    "        return res_explain, res_masks\n",
    "\n",
    "    def load_weights_from_unsupervised(self, unsupervised_model):\n",
    "        update_state_dict = copy.deepcopy(self.network.state_dict())\n",
    "        for param, weights in unsupervised_model.network.state_dict().items():\n",
    "            if param.startswith(\"encoder\"):\n",
    "                # Convert encoder's layers name to match\n",
    "                new_param = \"tabnet.\" + param\n",
    "            else:\n",
    "                new_param = param\n",
    "            if self.network.state_dict().get(new_param) is not None:\n",
    "                # update only common layers\n",
    "                update_state_dict[new_param] = weights\n",
    "\n",
    "        self.network.load_state_dict(update_state_dict)\n",
    "\n",
    "    def load_class_attrs(self, class_attrs):\n",
    "        for attr_name, attr_value in class_attrs.items():\n",
    "            setattr(self, attr_name, attr_value)\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"Saving TabNet model in two distinct files.\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "            Path of the model.\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            input filepath with \".zip\" appended\n",
    "        \"\"\"\n",
    "        saved_params = {}\n",
    "        init_params = {}\n",
    "        for key, val in self.get_params().items():\n",
    "            if isinstance(val, type):\n",
    "                # Don't save torch specific params\n",
    "                continue\n",
    "            else:\n",
    "                init_params[key] = val\n",
    "        saved_params[\"init_params\"] = init_params\n",
    "\n",
    "        class_attrs = {\n",
    "            \"preds_mapper\": self.preds_mapper\n",
    "        }\n",
    "        saved_params[\"class_attrs\"] = class_attrs\n",
    "\n",
    "        # Create folder\n",
    "        Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save models params\n",
    "        with open(Path(path).joinpath(\"model_params.json\"), \"w\", encoding=\"utf8\") as f:\n",
    "            json.dump(saved_params, f, cls=ComplexEncoder)\n",
    "\n",
    "        # Save state_dict\n",
    "        torch.save(self.network.state_dict(), Path(path).joinpath(\"network.pt\"))\n",
    "        shutil.make_archive(path, \"zip\", path)\n",
    "        shutil.rmtree(path)\n",
    "        print(f\"Successfully saved model at {path}.zip\")\n",
    "        return f\"{path}.zip\"\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"Load TabNet model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath : str\n",
    "            Path of the model.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with zipfile.ZipFile(filepath) as z:\n",
    "                with z.open(\"model_params.json\") as f:\n",
    "                    loaded_params = json.load(f)\n",
    "                    loaded_params[\"init_params\"][\"device_name\"] = self.device_name\n",
    "                with z.open(\"network.pt\") as f:\n",
    "                    try:\n",
    "                        saved_state_dict = torch.load(f, map_location=self.device)\n",
    "                    except io.UnsupportedOperation:\n",
    "                        # In Python <3.7, the returned file object is not seekable (which at least\n",
    "                        # some versions of PyTorch require) - so we'll try buffering it in to a\n",
    "                        # BytesIO instead:\n",
    "                        saved_state_dict = torch.load(\n",
    "                            io.BytesIO(f.read()),\n",
    "                            map_location=self.device,\n",
    "                        )\n",
    "        except KeyError:\n",
    "            raise KeyError(\"Your zip file is missing at least one component\")\n",
    "\n",
    "        self.__init__(**loaded_params[\"init_params\"])\n",
    "\n",
    "        self._set_network()\n",
    "        self.network.load_state_dict(saved_state_dict)\n",
    "        self.network.eval()\n",
    "        self.load_class_attrs(loaded_params[\"class_attrs\"])\n",
    "\n",
    "        return\n",
    "\n",
    "    def _train_epoch(self, train_loader):\n",
    "        \"\"\"\n",
    "        Trains one epoch of the network in self.network\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_loader : a :class: `torch.utils.data.Dataloader`\n",
    "            DataLoader with train set\n",
    "        \"\"\"\n",
    "        self.network.train()\n",
    "\n",
    "        for batch_idx, (X, y) in enumerate(train_loader):\n",
    "            self._callback_container.on_batch_begin(batch_idx)\n",
    "\n",
    "            batch_logs = self._train_batch(X, y)\n",
    "\n",
    "            self._callback_container.on_batch_end(batch_idx, batch_logs)\n",
    "\n",
    "        epoch_logs = {\"lr\": self._optimizer.param_groups[-1][\"lr\"]}\n",
    "        self.history.epoch_metrics.update(epoch_logs)\n",
    "\n",
    "        return\n",
    "\n",
    "    def _train_batch(self, X, y):\n",
    "        \"\"\"\n",
    "        Trains one batch of data\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch.Tensor\n",
    "            Train matrix\n",
    "        y : torch.Tensor\n",
    "            Target matrix\n",
    "        Returns\n",
    "        -------\n",
    "        batch_outs : dict\n",
    "            Dictionnary with \"y\": target and \"score\": prediction scores.\n",
    "        batch_logs : dict\n",
    "            Dictionnary with \"batch_size\" and \"loss\".\n",
    "        \"\"\"\n",
    "        batch_logs = {\"batch_size\": X.shape[0]}\n",
    "\n",
    "        X = X.to(self.device).float()\n",
    "        y = y.to(self.device).float()\n",
    "\n",
    "        if self.augmentations is not None:\n",
    "            X, y = self.augmentations(X, y)\n",
    "\n",
    "        for param in self.network.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        output, M_loss = self.network(X)\n",
    "\n",
    "        loss = self.compute_loss(output, y)\n",
    "        # Add the overall sparsity loss\n",
    "        loss = loss - self.lambda_sparse * M_loss\n",
    "\n",
    "        # Perform backward pass and optimization\n",
    "        loss.backward()\n",
    "        if self.clip_value:\n",
    "            clip_grad_norm_(self.network.parameters(), self.clip_value)\n",
    "        self._optimizer.step()\n",
    "\n",
    "        batch_logs[\"loss\"] = loss.cpu().detach().numpy().item()\n",
    "\n",
    "        return batch_logs\n",
    "\n",
    "    def _predict_epoch(self, name, loader):\n",
    "        \"\"\"\n",
    "        Predict an epoch and update metrics.\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            Name of the validation set\n",
    "        loader : torch.utils.data.Dataloader\n",
    "                DataLoader with validation set\n",
    "        \"\"\"\n",
    "        # Setting network on evaluation mode\n",
    "        self.network.eval()\n",
    "\n",
    "        list_y_true = []\n",
    "        list_y_score = []\n",
    "\n",
    "        # Main loop\n",
    "        for batch_idx, (X, y) in enumerate(loader):\n",
    "            scores = self._predict_batch(X)\n",
    "            list_y_true.append(y)\n",
    "            list_y_score.append(scores)\n",
    "\n",
    "        y_true, scores = self.stack_batches(list_y_true, list_y_score)\n",
    "\n",
    "        metrics_logs = self._metric_container_dict[name](y_true, scores)\n",
    "        self.network.train()\n",
    "        self.history.epoch_metrics.update(metrics_logs)\n",
    "        return\n",
    "\n",
    "    def _predict_batch(self, X):\n",
    "        \"\"\"\n",
    "        Predict one batch of data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch.Tensor\n",
    "            Owned products\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            model scores\n",
    "        \"\"\"\n",
    "        X = X.to(self.device).float()\n",
    "\n",
    "        # compute model output\n",
    "        scores, _ = self.network(X)\n",
    "\n",
    "        if isinstance(scores, list):\n",
    "            scores = [x.cpu().detach().numpy() for x in scores]\n",
    "        else:\n",
    "            scores = scores.cpu().detach().numpy()\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def _set_network(self):\n",
    "        \"\"\"Setup the network and explain matrix.\"\"\"\n",
    "        torch.manual_seed(self.seed)\n",
    "        self.network = tab_network.TabNet(\n",
    "            self.input_dim,\n",
    "            self.output_dim,\n",
    "            n_d=self.n_d,\n",
    "            n_a=self.n_a,\n",
    "            n_steps=self.n_steps,\n",
    "            gamma=self.gamma,\n",
    "            cat_idxs=self.cat_idxs,\n",
    "            cat_dims=self.cat_dims,\n",
    "            cat_emb_dim=self.cat_emb_dim,\n",
    "            n_independent=self.n_independent,\n",
    "            n_shared=self.n_shared,\n",
    "            epsilon=self.epsilon,\n",
    "            virtual_batch_size=self.virtual_batch_size,\n",
    "            momentum=self.momentum,\n",
    "            mask_type=self.mask_type,\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.reducing_matrix = create_explain_matrix(\n",
    "            self.network.input_dim,\n",
    "            self.network.cat_emb_dim,\n",
    "            self.network.cat_idxs,\n",
    "            self.network.post_embed_dim,\n",
    "        )\n",
    "\n",
    "    def _set_metrics(self, metrics, eval_names):\n",
    "        \"\"\"Set attributes relative to the metrics.\n",
    "        Parameters\n",
    "        ----------\n",
    "        metrics : list of str\n",
    "            List of eval metric names.\n",
    "        eval_names : list of str\n",
    "            List of eval set names.\n",
    "        \"\"\"\n",
    "        metrics = metrics or [self._default_metric]\n",
    "\n",
    "        metrics = check_metrics(metrics)\n",
    "        # Set metric container for each sets\n",
    "        self._metric_container_dict = {}\n",
    "        for name in eval_names:\n",
    "            self._metric_container_dict.update(\n",
    "                {name: MetricContainer(metrics, prefix=f\"{name}_\")}\n",
    "            )\n",
    "\n",
    "        self._metrics = []\n",
    "        self._metrics_names = []\n",
    "        for _, metric_container in self._metric_container_dict.items():\n",
    "            self._metrics.extend(metric_container.metrics)\n",
    "            self._metrics_names.extend(metric_container.names)\n",
    "\n",
    "        # Early stopping metric is the last eval metric\n",
    "        self.early_stopping_metric = (\n",
    "            self._metrics_names[-1] if len(self._metrics_names) > 0 else None\n",
    "        )\n",
    "\n",
    "    def _set_callbacks(self, custom_callbacks):\n",
    "        \"\"\"Setup the callbacks functions.\n",
    "        Parameters\n",
    "        ----------\n",
    "        custom_callbacks : list of func\n",
    "            List of callback functions.\n",
    "        \"\"\"\n",
    "        # Setup default callbacks history, early stopping and scheduler\n",
    "        callbacks = []\n",
    "        self.history = History(self, verbose=self.verbose)\n",
    "        callbacks.append(self.history)\n",
    "        if (self.early_stopping_metric is not None) and (self.patience > 0):\n",
    "            early_stopping = EarlyStopping(\n",
    "                early_stopping_metric=self.early_stopping_metric,\n",
    "                is_maximize=(\n",
    "                    self._metrics[-1]._maximize if len(self._metrics) > 0 else None\n",
    "                ),\n",
    "                patience=self.patience,\n",
    "            )\n",
    "            callbacks.append(early_stopping)\n",
    "        else:\n",
    "            wrn_msg = \"No early stopping will be performed, last training weights will be used.\"\n",
    "            warnings.warn(wrn_msg)\n",
    "\n",
    "        if self.scheduler_fn is not None:\n",
    "            # Add LR Scheduler call_back\n",
    "            is_batch_level = self.scheduler_params.pop(\"is_batch_level\", False)\n",
    "            scheduler = LRSchedulerCallback(\n",
    "                scheduler_fn=self.scheduler_fn,\n",
    "                scheduler_params=self.scheduler_params,\n",
    "                optimizer=self._optimizer,\n",
    "                early_stopping_metric=self.early_stopping_metric,\n",
    "                is_batch_level=is_batch_level,\n",
    "            )\n",
    "            callbacks.append(scheduler)\n",
    "\n",
    "        if custom_callbacks:\n",
    "            callbacks.extend(custom_callbacks)\n",
    "        self._callback_container = CallbackContainer(callbacks)\n",
    "        self._callback_container.set_trainer(self)\n",
    "\n",
    "    def _set_optimizer(self):\n",
    "        \"\"\"Setup optimizer.\"\"\"\n",
    "        self._optimizer = self.optimizer_fn(\n",
    "            self.network.parameters(), **self.optimizer_params\n",
    "        )\n",
    "\n",
    "    def _construct_loaders(self, X_train, y_train, eval_set):\n",
    "        \"\"\"Generate dataloaders for train and eval set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.array\n",
    "            Train set.\n",
    "        y_train : np.array\n",
    "            Train targets.\n",
    "        eval_set : list of tuple\n",
    "            List of eval tuple set (X, y).\n",
    "        Returns\n",
    "        -------\n",
    "        train_dataloader : `torch.utils.data.Dataloader`\n",
    "            Training dataloader.\n",
    "        valid_dataloaders : list of `torch.utils.data.Dataloader`\n",
    "            List of validation dataloaders.\n",
    "        \"\"\"\n",
    "        # all weights are not allowed for this type of model\n",
    "        y_train_mapped = self.prepare_target(y_train)\n",
    "        for i, (X, y) in enumerate(eval_set):\n",
    "            y_mapped = self.prepare_target(y)\n",
    "            eval_set[i] = (X, y_mapped)\n",
    "\n",
    "        train_dataloader, valid_dataloaders = create_dataloaders(\n",
    "            X_train,\n",
    "            y_train_mapped,\n",
    "            eval_set,\n",
    "            self.updated_weights,\n",
    "            self.batch_size,\n",
    "            self.num_workers,\n",
    "            self.drop_last,\n",
    "            self.pin_memory,\n",
    "        )\n",
    "        return train_dataloader, valid_dataloaders\n",
    "\n",
    "    def _compute_feature_importances(self, X):\n",
    "        \"\"\"Compute global feature importance.\n",
    "        Parameters\n",
    "        ----------\n",
    "        loader : `torch.utils.data.Dataloader`\n",
    "            Pytorch dataloader.\n",
    "        \"\"\"\n",
    "        M_explain, _ = self.explain(X, normalize=False)\n",
    "        sum_explain = M_explain.sum(axis=0)\n",
    "        feature_importances_ = sum_explain / np.sum(sum_explain)\n",
    "        return feature_importances_\n",
    "\n",
    "    def _update_network_params(self):\n",
    "        self.network.virtual_batch_size = self.virtual_batch_size\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_fit_params(self, X_train, y_train, eval_set, weights):\n",
    "        \"\"\"\n",
    "        Set attributes relative to fit function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray\n",
    "            Train set\n",
    "        y_train : np.array\n",
    "            Train targets\n",
    "        eval_set : list of tuple\n",
    "            List of eval tuple set (X, y).\n",
    "        weights : bool or dictionnary\n",
    "            0 for no balancing\n",
    "            1 for automated balancing\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"users must define update_fit_params to use this base class\"\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def compute_loss(self, y_score, y_true):\n",
    "        \"\"\"\n",
    "        Compute the loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_score : a :tensor: `torch.Tensor`\n",
    "            Score matrix\n",
    "        y_true : a :tensor: `torch.Tensor`\n",
    "            Target matrix\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Loss value\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"users must define compute_loss to use this base class\"\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def prepare_target(self, y):\n",
    "        \"\"\"\n",
    "        Prepare target before training.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : a :tensor: `torch.Tensor`\n",
    "            Target matrix.\n",
    "        Returns\n",
    "        -------\n",
    "        `torch.Tensor`\n",
    "            Converted target matrix.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"users must define prepare_target to use this base class\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, BatchNorm1d, ReLU, LeakyReLU\n",
    "import numpy as np\n",
    "from pytorch_tabnet import sparsemax\n",
    "\n",
    "\n",
    "def initialize_non_glu(module, input_dim, output_dim):\n",
    "    gain_value = np.sqrt((input_dim + output_dim) / np.sqrt(4 * input_dim))\n",
    "    torch.nn.init.xavier_normal_(module.weight, gain=gain_value)\n",
    "    # torch.nn.init.zeros_(module.bias)\n",
    "    return\n",
    "\n",
    "\n",
    "def initialize_glu(module, input_dim, output_dim):\n",
    "    gain_value = np.sqrt((input_dim + output_dim) / np.sqrt(input_dim))\n",
    "    torch.nn.init.xavier_normal_(module.weight, gain=gain_value)\n",
    "    # torch.nn.init.zeros_(module.bias)\n",
    "    return\n",
    "\n",
    "\n",
    "class GBN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Ghost Batch Normalization\n",
    "    https://arxiv.org/abs/1705.08741\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, virtual_batch_size=128, momentum=0.01):\n",
    "        super(GBN, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.bn = BatchNorm1d(self.input_dim, momentum=momentum)\n",
    "\n",
    "    def forward(self, x):\n",
    "        chunks = x.chunk(int(np.ceil(x.shape[0] / self.virtual_batch_size)), 0)\n",
    "        res = [self.bn(x_) for x_ in chunks]\n",
    "\n",
    "        return torch.cat(res, dim=0)\n",
    "\n",
    "\n",
    "class TabNetEncoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        n_d=100,\n",
    "        n_a=100,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=3,\n",
    "        n_shared=5,\n",
    "        epsilon=1e-15,\n",
    "        virtual_batch_size=128,\n",
    "        momentum=0.02,\n",
    "        mask_type=\"entmax\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Defines main part of the TabNet network without the embedding layers.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : int\n",
    "            Number of features\n",
    "        output_dim : int or list of int for multi task classification\n",
    "            Dimension of network output\n",
    "            examples : one for regression, 2 for binary classification etc...\n",
    "        n_d : int\n",
    "            Dimension of the prediction  layer (usually between 4 and 64)\n",
    "        n_a : int\n",
    "            Dimension of the attention  layer (usually between 4 and 64)\n",
    "        n_steps : int\n",
    "            Number of successive steps in the network (usually between 3 and 10)\n",
    "        gamma : float\n",
    "            Float above 1, scaling factor for attention updates (usually between 1.0 to 2.0)\n",
    "        n_independent : int\n",
    "            Number of independent GLU layer in each GLU block (default 2)\n",
    "        n_shared : int\n",
    "            Number of independent GLU layer in each GLU block (default 2)\n",
    "        epsilon : float\n",
    "            Avoid log(0), this should be kept very low\n",
    "        virtual_batch_size : int\n",
    "            Batch size for Ghost Batch Normalization\n",
    "        momentum : float\n",
    "            Float value between 0 and 1 which will be used for momentum in all batch norm\n",
    "        mask_type : str\n",
    "            Either \"sparsemax\" or \"entmax\" : this is the masking function to use\n",
    "        \"\"\"\n",
    "        super(TabNetEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.is_multi_task = isinstance(output_dim, list)\n",
    "        self.n_d = n_d\n",
    "        self.n_a = n_a\n",
    "        self.n_steps = n_steps\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.n_independent = n_independent\n",
    "        self.n_shared = n_shared\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.mask_type = mask_type\n",
    "        self.initial_bn = BatchNorm1d(self.input_dim, momentum=0.015)\n",
    "\n",
    "        if self.n_shared > 0:\n",
    "            shared_feat_transform = torch.nn.ModuleList()\n",
    "            for i in range(self.n_shared):\n",
    "                if i == 0:\n",
    "                    shared_feat_transform.append(\n",
    "                        Linear(self.input_dim, 2 * (n_d + n_a), bias=False)\n",
    "                    )\n",
    "                else:\n",
    "                    shared_feat_transform.append(\n",
    "                        Linear(n_d + n_a, 2 * (n_d + n_a), bias=False)\n",
    "                    )\n",
    "\n",
    "        else:\n",
    "            shared_feat_transform = None\n",
    "\n",
    "        self.initial_splitter = FeatTransformer(\n",
    "            self.input_dim,\n",
    "            n_d + n_a,\n",
    "            shared_feat_transform,\n",
    "            n_glu_independent=self.n_independent,\n",
    "            virtual_batch_size=self.virtual_batch_size,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "\n",
    "        self.feat_transformers = torch.nn.ModuleList()\n",
    "        self.att_transformers = torch.nn.ModuleList()\n",
    "\n",
    "        for step in range(n_steps):\n",
    "            transformer = FeatTransformer(\n",
    "                self.input_dim,\n",
    "                n_d + n_a,\n",
    "                shared_feat_transform,\n",
    "                n_glu_independent=self.n_independent,\n",
    "                virtual_batch_size=self.virtual_batch_size,\n",
    "                momentum=momentum,\n",
    "            )\n",
    "            attention = AttentiveTransformer(\n",
    "                n_a,\n",
    "                self.input_dim,\n",
    "                virtual_batch_size=self.virtual_batch_size,\n",
    "                momentum=momentum,\n",
    "                mask_type=self.mask_type,\n",
    "            )\n",
    "            self.feat_transformers.append(transformer)\n",
    "            self.att_transformers.append(attention)\n",
    "\n",
    "    def forward(self, x, prior=None):\n",
    "        x = self.initial_bn(x)\n",
    "\n",
    "        if prior is None:\n",
    "            prior = torch.ones(x.shape).to(x.device)\n",
    "\n",
    "        M_loss = 0\n",
    "        att = self.initial_splitter(x)[:, self.n_d :]\n",
    "\n",
    "        steps_output = []\n",
    "        for step in range(self.n_steps):\n",
    "            M = self.att_transformers[step](prior, att)\n",
    "            M_loss += torch.mean(\n",
    "                torch.sum(torch.mul(M, torch.log(M + self.epsilon)), dim=1)\n",
    "            )\n",
    "            # update prior\n",
    "            prior = torch.mul(self.gamma - M, prior)\n",
    "            # output\n",
    "            masked_x = torch.mul(M, x)\n",
    "            out = self.feat_transformers[step](masked_x)\n",
    "            d = LeakyReLU(negative_slope=0.02)(out[:, : self.n_d])\n",
    "            steps_output.append(d)\n",
    "            # update attention\n",
    "            att = out[:, self.n_d :]\n",
    "\n",
    "        M_loss /= self.n_steps\n",
    "        return steps_output, M_loss\n",
    "\n",
    "    def forward_masks(self, x):\n",
    "        x = self.initial_bn(x)\n",
    "\n",
    "        prior = torch.ones(x.shape).to(x.device)\n",
    "        M_explain = torch.zeros(x.shape).to(x.device)\n",
    "        att = self.initial_splitter(x)[:, self.n_d :]\n",
    "        masks = {}\n",
    "\n",
    "        for step in range(self.n_steps):\n",
    "            M = self.att_transformers[step](prior, att)\n",
    "            masks[step] = M\n",
    "            # update prior\n",
    "            prior = torch.mul(self.gamma - M, prior)\n",
    "            # output\n",
    "            masked_x = torch.mul(M, x)\n",
    "            out = self.feat_transformers[step](masked_x)\n",
    "            d = LeakyReLU(negative_slope=0.02)(out[:, : self.n_d])\n",
    "            # explain\n",
    "            step_importance = torch.sum(d, dim=1)\n",
    "            M_explain += torch.mul(M, step_importance.unsqueeze(dim=1))\n",
    "            # update attention\n",
    "            att = out[:, self.n_d :]\n",
    "\n",
    "        return M_explain, masks\n",
    "\n",
    "\n",
    "class TabNetDecoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        n_d=100,\n",
    "        n_steps=3,\n",
    "        n_independent=2,\n",
    "        n_shared=2,\n",
    "        virtual_batch_size=128,\n",
    "        momentum=0.02,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Defines main part of the TabNet network without the embedding layers.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : int\n",
    "            Number of features\n",
    "        output_dim : int or list of int for multi task classification\n",
    "            Dimension of network output\n",
    "            examples : one for regression, 2 for binary classification etc...\n",
    "        n_d : int\n",
    "            Dimension of the prediction  layer (usually between 4 and 64)\n",
    "        n_steps : int\n",
    "            Number of successive steps in the network (usually between 3 and 10)\n",
    "        gamma : float\n",
    "            Float above 1, scaling factor for attention updates (usually between 1.0 to 2.0)\n",
    "        n_independent : int\n",
    "            Number of independent GLU layer in each GLU block (default 1)\n",
    "        n_shared : int\n",
    "            Number of independent GLU layer in each GLU block (default 1)\n",
    "        virtual_batch_size : int\n",
    "            Batch size for Ghost Batch Normalization\n",
    "        momentum : float\n",
    "            Float value between 0 and 1 which will be used for momentum in all batch norm\n",
    "        \"\"\"\n",
    "        super(TabNetDecoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.n_d = n_d\n",
    "        self.n_steps = n_steps\n",
    "        self.n_independent = n_independent\n",
    "        self.n_shared = n_shared\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "\n",
    "        self.feat_transformers = torch.nn.ModuleList()\n",
    "\n",
    "        if self.n_shared > 0:\n",
    "            shared_feat_transform = torch.nn.ModuleList()\n",
    "            for i in range(self.n_shared):\n",
    "                if i == 0:\n",
    "                    shared_feat_transform.append(Linear(n_d, 2 * n_d, bias=False))\n",
    "                else:\n",
    "                    shared_feat_transform.append(Linear(n_d, 2 * n_d, bias=False))\n",
    "\n",
    "        else:\n",
    "            shared_feat_transform = None\n",
    "\n",
    "        for step in range(n_steps):\n",
    "            transformer = FeatTransformer(\n",
    "                n_d,\n",
    "                n_d,\n",
    "                shared_feat_transform,\n",
    "                n_glu_independent=self.n_independent,\n",
    "                virtual_batch_size=self.virtual_batch_size,\n",
    "                momentum=momentum,\n",
    "            )\n",
    "            self.feat_transformers.append(transformer)\n",
    "\n",
    "        self.reconstruction_layer = Linear(n_d, self.input_dim, bias=False)\n",
    "        initialize_non_glu(self.reconstruction_layer, n_d, self.input_dim)\n",
    "\n",
    "    def forward(self, steps_output):\n",
    "        res = 0\n",
    "        for step_nb, step_output in enumerate(steps_output):\n",
    "            x = self.feat_transformers[step_nb](step_output)\n",
    "            res = torch.add(res, x)\n",
    "        res = self.reconstruction_layer(res)\n",
    "        return res\n",
    "\n",
    "\n",
    "class TabNetPretraining(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        pretraining_ratio=0.2,\n",
    "        n_d=100,\n",
    "        n_a=100,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        cat_idxs=[],\n",
    "        cat_dims=[],\n",
    "        cat_emb_dim=1,\n",
    "        n_independent=5,\n",
    "        n_shared=5,\n",
    "        epsilon=1e-15,\n",
    "        virtual_batch_size=128,\n",
    "        momentum=0.02,\n",
    "        mask_type=\"entmax\",\n",
    "        n_shared_decoder=2,\n",
    "        n_indep_decoder=2,\n",
    "    ):\n",
    "        super(TabNetPretraining, self).__init__()\n",
    "\n",
    "        self.cat_idxs = cat_idxs or []\n",
    "        self.cat_dims = cat_dims or []\n",
    "        self.cat_emb_dim = cat_emb_dim\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.n_d = n_d\n",
    "        self.n_a = n_a\n",
    "        self.n_steps = n_steps\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.n_independent = n_independent\n",
    "        self.n_shared = n_shared\n",
    "        self.mask_type = mask_type\n",
    "        self.pretraining_ratio = pretraining_ratio\n",
    "        self.n_shared_decoder = n_shared_decoder\n",
    "        self.n_indep_decoder = n_indep_decoder\n",
    "\n",
    "        if self.n_steps <= 0:\n",
    "            raise ValueError(\"n_steps should be a positive integer.\")\n",
    "        if self.n_independent == 0 and self.n_shared == 0:\n",
    "            raise ValueError(\"n_shared and n_independent can't be both zero.\")\n",
    "\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.embedder = EmbeddingGenerator(input_dim, cat_dims, cat_idxs, cat_emb_dim)\n",
    "        self.post_embed_dim = self.embedder.post_embed_dim\n",
    "\n",
    "        self.masker = RandomObfuscator(self.pretraining_ratio)\n",
    "        self.encoder = TabNetEncoder(\n",
    "            input_dim=self.post_embed_dim,\n",
    "            output_dim=self.post_embed_dim,\n",
    "            n_d=n_d,\n",
    "            n_a=n_a,\n",
    "            n_steps=n_steps,\n",
    "            gamma=gamma,\n",
    "            n_independent=n_independent,\n",
    "            n_shared=n_shared,\n",
    "            epsilon=epsilon,\n",
    "            virtual_batch_size=virtual_batch_size,\n",
    "            momentum=momentum,\n",
    "            mask_type=mask_type,\n",
    "        )\n",
    "        self.decoder = TabNetDecoder(\n",
    "            self.post_embed_dim,\n",
    "            n_d=n_d,\n",
    "            n_steps=n_steps,\n",
    "            n_independent=self.n_indep_decoder,\n",
    "            n_shared=self.n_shared_decoder,\n",
    "            virtual_batch_size=virtual_batch_size,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Returns: res, embedded_x, obf_vars\n",
    "            res : output of reconstruction\n",
    "            embedded_x : embedded input\n",
    "            obf_vars : which variable where obfuscated\n",
    "        \"\"\"\n",
    "        embedded_x = self.embedder(x)\n",
    "        if self.training:\n",
    "            masked_x, obf_vars = self.masker(embedded_x)\n",
    "            # set prior of encoder with obf_mask\n",
    "            prior = 1 - obf_vars\n",
    "            steps_out, _ = self.encoder(masked_x, prior=prior)\n",
    "            res = self.decoder(steps_out)\n",
    "            return res, embedded_x, obf_vars\n",
    "        else:\n",
    "            steps_out, _ = self.encoder(embedded_x)\n",
    "            res = self.decoder(steps_out)\n",
    "            return res, embedded_x, torch.ones(embedded_x.shape).to(x.device)\n",
    "\n",
    "    def forward_masks(self, x):\n",
    "        embedded_x = self.embedder(x)\n",
    "        return self.encoder.forward_masks(embedded_x)\n",
    "\n",
    "\n",
    "class TabNetNoEmbeddings(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        n_d=100,\n",
    "        n_a=100,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        n_independent=5,\n",
    "        n_shared=5,\n",
    "        epsilon=1e-15,\n",
    "        virtual_batch_size=128,\n",
    "        momentum=0.02,\n",
    "        mask_type=\"entmax\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Defines main part of the TabNet network without the embedding layers.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : int\n",
    "            Number of features\n",
    "        output_dim : int or list of int for multi task classification\n",
    "            Dimension of network output\n",
    "            examples : one for regression, 2 for binary classification etc...\n",
    "        n_d : int\n",
    "            Dimension of the prediction  layer (usually between 4 and 64)\n",
    "        n_a : int\n",
    "            Dimension of the attention  layer (usually between 4 and 64)\n",
    "        n_steps : int\n",
    "            Number of successive steps in the network (usually between 3 and 10)\n",
    "        gamma : float\n",
    "            Float above 1, scaling factor for attention updates (usually between 1.0 to 2.0)\n",
    "        n_independent : int\n",
    "            Number of independent GLU layer in each GLU block (default 2)\n",
    "        n_shared : int\n",
    "            Number of independent GLU layer in each GLU block (default 2)\n",
    "        epsilon : float\n",
    "            Avoid log(0), this should be kept very low\n",
    "        virtual_batch_size : int\n",
    "            Batch size for Ghost Batch Normalization\n",
    "        momentum : float\n",
    "            Float value between 0 and 1 which will be used for momentum in all batch norm\n",
    "        mask_type : str\n",
    "            Either \"sparsemax\" or \"entmax\" : this is the masking function to use\n",
    "        \"\"\"\n",
    "        super(TabNetNoEmbeddings, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.is_multi_task = isinstance(output_dim, list)\n",
    "        self.n_d = n_d\n",
    "        self.n_a = n_a\n",
    "        self.n_steps = n_steps\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.n_independent = n_independent\n",
    "        self.n_shared = n_shared\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.mask_type = mask_type\n",
    "        self.initial_bn = BatchNorm1d(self.input_dim, momentum=0.01)\n",
    "\n",
    "        self.encoder = TabNetEncoder(\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim,\n",
    "            n_d=n_d,\n",
    "            n_a=n_a,\n",
    "            n_steps=n_steps,\n",
    "            gamma=gamma,\n",
    "            n_independent=n_independent,\n",
    "            n_shared=n_shared,\n",
    "            epsilon=epsilon,\n",
    "            virtual_batch_size=virtual_batch_size,\n",
    "            momentum=momentum,\n",
    "            mask_type=mask_type,\n",
    "        )\n",
    "\n",
    "        if self.is_multi_task:\n",
    "            self.multi_task_mappings = torch.nn.ModuleList()\n",
    "            for task_dim in output_dim:\n",
    "                task_mapping = Linear(n_d, task_dim, bias=False)\n",
    "                initialize_non_glu(task_mapping, n_d, task_dim)\n",
    "                self.multi_task_mappings.append(task_mapping)\n",
    "        else:\n",
    "            self.final_mapping = Linear(n_d, output_dim, bias=False)\n",
    "            initialize_non_glu(self.final_mapping, n_d, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = 0\n",
    "        steps_output, M_loss = self.encoder(x)\n",
    "        res = torch.sum(torch.stack(steps_output, dim=0), dim=0)\n",
    "\n",
    "        if self.is_multi_task:\n",
    "            # Result will be in list format\n",
    "            out = []\n",
    "            for task_mapping in self.multi_task_mappings:\n",
    "                out.append(task_mapping(res))\n",
    "        else:\n",
    "            out = self.final_mapping(res)\n",
    "        return out, M_loss\n",
    "\n",
    "    def forward_masks(self, x):\n",
    "        return self.encoder.forward_masks(x)\n",
    "\n",
    "\n",
    "class TabNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        n_d=100,\n",
    "        n_a=100,\n",
    "        n_steps=3,\n",
    "        gamma=1.3,\n",
    "        cat_idxs=[],\n",
    "        cat_dims=[],\n",
    "        cat_emb_dim=1,\n",
    "        n_independent=3,\n",
    "        n_shared=3,\n",
    "        epsilon=1e-15,\n",
    "        virtual_batch_size=128,\n",
    "        momentum=0.02,\n",
    "        mask_type=\"entmax\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Defines TabNet network\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : int\n",
    "            Initial number of features\n",
    "        output_dim : int\n",
    "            Dimension of network output\n",
    "            examples : one for regression, 2 for binary classification etc...\n",
    "        n_d : int\n",
    "            Dimension of the prediction  layer (usually between 4 and 64)\n",
    "        n_a : int\n",
    "            Dimension of the attention  layer (usually between 4 and 64)\n",
    "        n_steps : int\n",
    "            Number of successive steps in the network (usually between 3 and 10)\n",
    "        gamma : float\n",
    "            Float above 1, scaling factor for attention updates (usually between 1.0 to 2.0)\n",
    "        cat_idxs : list of int\n",
    "            Index of each categorical column in the dataset\n",
    "        cat_dims : list of int\n",
    "            Number of categories in each categorical column\n",
    "        cat_emb_dim : int or list of int\n",
    "            Size of the embedding of categorical features\n",
    "            if int, all categorical features will have same embedding size\n",
    "            if list of int, every corresponding feature will have specific size\n",
    "        n_independent : int\n",
    "            Number of independent GLU layer in each GLU block (default 2)\n",
    "        n_shared : int\n",
    "            Number of independent GLU layer in each GLU block (default 2)\n",
    "        epsilon : float\n",
    "            Avoid log(0), this should be kept very low\n",
    "        virtual_batch_size : int\n",
    "            Batch size for Ghost Batch Normalization\n",
    "        momentum : float\n",
    "            Float value between 0 and 1 which will be used for momentum in all batch norm\n",
    "        mask_type : str\n",
    "            Either \"sparsemax\" or \"entmax\" : this is the masking function to use\n",
    "        \"\"\"\n",
    "        super(TabNet, self).__init__()\n",
    "        self.cat_idxs = cat_idxs or []\n",
    "        self.cat_dims = cat_dims or []\n",
    "        self.cat_emb_dim = cat_emb_dim\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_d = n_d\n",
    "        self.n_a = n_a\n",
    "        self.n_steps = n_steps\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.n_independent = n_independent\n",
    "        self.n_shared = n_shared\n",
    "        self.mask_type = mask_type\n",
    "\n",
    "        if self.n_steps <= 0:\n",
    "            raise ValueError(\"n_steps should be a positive integer.\")\n",
    "        if self.n_independent == 0 and self.n_shared == 0:\n",
    "            raise ValueError(\"n_shared and n_independent can't be both zero.\")\n",
    "\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.embedder = EmbeddingGenerator(input_dim, cat_dims, cat_idxs, cat_emb_dim)\n",
    "        self.post_embed_dim = self.embedder.post_embed_dim\n",
    "        self.tabnet = TabNetNoEmbeddings(\n",
    "            self.post_embed_dim,\n",
    "            output_dim,\n",
    "            n_d,\n",
    "            n_a,\n",
    "            n_steps,\n",
    "            gamma,\n",
    "            n_independent,\n",
    "            n_shared,\n",
    "            epsilon,\n",
    "            virtual_batch_size,\n",
    "            momentum,\n",
    "            mask_type,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedder(x)\n",
    "        return self.tabnet(x)\n",
    "\n",
    "    def forward_masks(self, x):\n",
    "        x = self.embedder(x)\n",
    "        return self.tabnet.forward_masks(x)\n",
    "\n",
    "\n",
    "class AttentiveTransformer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        virtual_batch_size=256,\n",
    "        momentum=0.02,\n",
    "        mask_type=\"entmax\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize an attention transformer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : int\n",
    "            Input size\n",
    "        output_dim : int\n",
    "            Output_size\n",
    "        virtual_batch_size : int\n",
    "            Batch size for Ghost Batch Normalization\n",
    "        momentum : float\n",
    "            Float value between 0 and 1 which will be used for momentum in batch norm\n",
    "        mask_type : str\n",
    "            Either \"sparsemax\" or \"entmax\" : this is the masking function to use\n",
    "        \"\"\"\n",
    "        super(AttentiveTransformer, self).__init__()\n",
    "        self.fc = Linear(input_dim, output_dim, bias=False)\n",
    "        initialize_non_glu(self.fc, input_dim, output_dim)\n",
    "        self.bn = GBN(\n",
    "            output_dim, virtual_batch_size=virtual_batch_size, momentum=momentum\n",
    "        )\n",
    "\n",
    "        if mask_type == \"sparsemax\":\n",
    "            # Sparsemax\n",
    "            self.selector = sparsemax.Sparsemax(dim=-1)\n",
    "        elif mask_type == \"entmax\":\n",
    "            # Entmax\n",
    "            self.selector = sparsemax.Entmax15(dim=-1)\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                \"Please choose either sparsemax\" + \"or entmax as masktype\"\n",
    "            )\n",
    "\n",
    "    def forward(self, priors, processed_feat):\n",
    "        x = self.fc(processed_feat)\n",
    "        x = self.bn(x)\n",
    "        x = torch.mul(x, priors)\n",
    "        x = self.selector(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FeatTransformer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        shared_layers,\n",
    "        n_glu_independent,\n",
    "        virtual_batch_size=256,\n",
    "        momentum=0.02,\n",
    "    ):\n",
    "        super(FeatTransformer, self).__init__()\n",
    "        \"\"\"\n",
    "        Initialize a feature transformer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : int\n",
    "            Input size\n",
    "        output_dim : int\n",
    "            Output_size\n",
    "        shared_layers : torch.nn.ModuleList\n",
    "            The shared block that should be common to every step\n",
    "        n_glu_independent : int\n",
    "            Number of independent GLU layers\n",
    "        virtual_batch_size : int\n",
    "            Batch size for Ghost Batch Normalization within GLU block(s)\n",
    "        momentum : float\n",
    "            Float value between 0 and 1 which will be used for momentum in batch norm\n",
    "        \"\"\"\n",
    "\n",
    "        params = {\n",
    "            \"n_glu\": n_glu_independent,\n",
    "            \"virtual_batch_size\": virtual_batch_size,\n",
    "            \"momentum\": momentum,\n",
    "        }\n",
    "\n",
    "        if shared_layers is None:\n",
    "            # no shared layers\n",
    "            self.shared = torch.nn.Identity()\n",
    "            is_first = True\n",
    "        else:\n",
    "            self.shared = GLU_Block(\n",
    "                input_dim,\n",
    "                output_dim,\n",
    "                first=True,\n",
    "                shared_layers=shared_layers,\n",
    "                n_glu=len(shared_layers),\n",
    "                virtual_batch_size=virtual_batch_size,\n",
    "                momentum=momentum,\n",
    "            )\n",
    "            is_first = False\n",
    "\n",
    "        if n_glu_independent == 0:\n",
    "            # no independent layers\n",
    "            self.specifics = torch.nn.Identity()\n",
    "        else:\n",
    "            spec_input_dim = input_dim if is_first else output_dim\n",
    "            self.specifics = GLU_Block(\n",
    "                spec_input_dim, output_dim, first=is_first, **params\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.shared(x)\n",
    "        x = self.specifics(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GLU_Block(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Independent GLU block, specific to each step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        n_glu=5,\n",
    "        first=False,\n",
    "        shared_layers=None,\n",
    "        virtual_batch_size=256,\n",
    "        momentum=0.02,\n",
    "    ):\n",
    "        super(GLU_Block, self).__init__()\n",
    "        self.first = first\n",
    "        self.shared_layers = shared_layers\n",
    "        self.n_glu = n_glu\n",
    "        self.glu_layers = torch.nn.ModuleList()\n",
    "\n",
    "        params = {\"virtual_batch_size\": virtual_batch_size, \"momentum\": momentum}\n",
    "\n",
    "        fc = shared_layers[0] if shared_layers else None\n",
    "        self.glu_layers.append(GLU_Layer(input_dim, output_dim, fc=fc, **params))\n",
    "        for glu_id in range(1, self.n_glu):\n",
    "            fc = shared_layers[glu_id] if shared_layers else None\n",
    "            self.glu_layers.append(GLU_Layer(output_dim, output_dim, fc=fc, **params))\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = torch.sqrt(torch.FloatTensor([0.5]).to(x.device))\n",
    "        if self.first:  # the first layer of the block has no scale multiplication\n",
    "            x = self.glu_layers[0](x)\n",
    "            layers_left = range(1, self.n_glu)\n",
    "        else:\n",
    "            layers_left = range(self.n_glu)\n",
    "\n",
    "        for glu_id in layers_left:\n",
    "            x = torch.add(x, self.glu_layers[glu_id](x))\n",
    "            x = x * scale\n",
    "        return x\n",
    "\n",
    "\n",
    "class GLU_Layer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim, output_dim, fc=None, virtual_batch_size=128, momentum=0.03\n",
    "    ):\n",
    "        super(GLU_Layer, self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        if fc:\n",
    "            self.fc = fc\n",
    "        else:\n",
    "            self.fc = Linear(input_dim, 2 * output_dim, bias=False)\n",
    "        initialize_glu(self.fc, input_dim, 2 * output_dim)\n",
    "\n",
    "        self.bn = GBN(\n",
    "            2 * output_dim, virtual_batch_size=virtual_batch_size, momentum=momentum\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.bn(x)\n",
    "        out = torch.mul(x[:, : self.output_dim], torch.sigmoid(x[:, self.output_dim :]))\n",
    "        return out\n",
    "\n",
    "\n",
    "class EmbeddingGenerator(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Classical embeddings generator\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, cat_dims, cat_idxs, cat_emb_dim):\n",
    "        \"\"\"This is an embedding module for an entire set of features\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : int\n",
    "            Number of features coming as input (number of columns)\n",
    "        cat_dims : list of int\n",
    "            Number of modalities for each categorial features\n",
    "            If the list is empty, no embeddings will be done\n",
    "        cat_idxs : list of int\n",
    "            Positional index for each categorical features in inputs\n",
    "        cat_emb_dim : int or list of int\n",
    "            Embedding dimension for each categorical features\n",
    "            If int, the same embedding dimension will be used for all categorical features\n",
    "        \"\"\"\n",
    "        super(EmbeddingGenerator, self).__init__()\n",
    "        if cat_dims == [] and cat_idxs == []:\n",
    "            self.skip_embedding = True\n",
    "            self.post_embed_dim = input_dim\n",
    "            return\n",
    "        elif (cat_dims == []) ^ (cat_idxs == []):\n",
    "            if cat_dims == []:\n",
    "                msg = \"If cat_idxs is non-empty, cat_dims must be defined as a list of same length.\"\n",
    "            else:\n",
    "                msg = \"If cat_dims is non-empty, cat_idxs must be defined as a list of same length.\"\n",
    "            raise ValueError(msg)\n",
    "        elif len(cat_dims) != len(cat_idxs):\n",
    "            msg = \"The lists cat_dims and cat_idxs must have the same length.\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.skip_embedding = False\n",
    "        if isinstance(cat_emb_dim, int):\n",
    "            self.cat_emb_dims = [cat_emb_dim] * len(cat_idxs)\n",
    "        else:\n",
    "            self.cat_emb_dims = cat_emb_dim\n",
    "\n",
    "        # check that all embeddings are provided\n",
    "        if len(self.cat_emb_dims) != len(cat_dims):\n",
    "            msg = f\"\"\"cat_emb_dim and cat_dims must be lists of same length, got {len(self.cat_emb_dims)}\n",
    "                      and {len(cat_dims)}\"\"\"\n",
    "            raise ValueError(msg)\n",
    "        self.post_embed_dim = int(\n",
    "            input_dim + np.sum(self.cat_emb_dims) - len(self.cat_emb_dims)\n",
    "        )\n",
    "\n",
    "        self.embeddings = torch.nn.ModuleList()\n",
    "\n",
    "        # Sort dims by cat_idx\n",
    "        sorted_idxs = np.argsort(cat_idxs)\n",
    "        cat_dims = [cat_dims[i] for i in sorted_idxs]\n",
    "        self.cat_emb_dims = [self.cat_emb_dims[i] for i in sorted_idxs]\n",
    "\n",
    "        for cat_dim, emb_dim in zip(cat_dims, self.cat_emb_dims):\n",
    "            self.embeddings.append(torch.nn.Embedding(cat_dim, emb_dim))\n",
    "\n",
    "        # record continuous indices\n",
    "        self.continuous_idx = torch.ones(input_dim, dtype=torch.bool)\n",
    "        self.continuous_idx[cat_idxs] = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Apply embeddings to inputs\n",
    "        Inputs should be (batch_size, input_dim)\n",
    "        Outputs will be of size (batch_size, self.post_embed_dim)\n",
    "        \"\"\"\n",
    "        if self.skip_embedding:\n",
    "            # no embeddings required\n",
    "            return x\n",
    "\n",
    "        cols = []\n",
    "        cat_feat_counter = 0\n",
    "        for feat_init_idx, is_continuous in enumerate(self.continuous_idx):\n",
    "            # Enumerate through continuous idx boolean mask to apply embeddings\n",
    "            if is_continuous:\n",
    "                cols.append(x[:, feat_init_idx].float().view(-1, 1))\n",
    "            else:\n",
    "                cols.append(\n",
    "                    self.embeddings[cat_feat_counter](x[:, feat_init_idx].long())\n",
    "                )\n",
    "                cat_feat_counter += 1\n",
    "        # concat\n",
    "        post_embeddings = torch.cat(cols, dim=1)\n",
    "        return post_embeddings\n",
    "\n",
    "\n",
    "class RandomObfuscator(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Create and applies obfuscation masks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pretraining_ratio):\n",
    "        \"\"\"\n",
    "        This create random obfuscation for self suppervised pretraining\n",
    "        Parameters\n",
    "        ----------\n",
    "        pretraining_ratio : float\n",
    "            Ratio of feature to randomly discard for reconstruction\n",
    "        \"\"\"\n",
    "        super(RandomObfuscator, self).__init__()\n",
    "        self.pretraining_ratio = pretraining_ratio\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Generate random obfuscation mask.\n",
    "        Returns\n",
    "        -------\n",
    "        masked input and obfuscated variables.\n",
    "        \"\"\"\n",
    "        obfuscated_vars = torch.bernoulli(\n",
    "            self.pretraining_ratio * torch.ones(x.shape)\n",
    "        ).to(x.device)\n",
    "        masked_input = torch.mul(1 - obfuscated_vars, x)\n",
    "        return masked_input, obfuscated_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from pytorch_tabnet.utils import PredictDataset, filter_weights\n",
    "from pytorch_tabnet.multiclass_utils import infer_output_dim, check_output_dim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class TabNetClassifier(TabModel):\n",
    "    def __post_init__(self):\n",
    "        super(TabNetClassifier, self).__post_init__()\n",
    "        self._task = 'classification'\n",
    "        self._default_loss = torch.nn.functional.cross_entropy\n",
    "        self._default_metric = 'accuracy'\n",
    "\n",
    "    def weight_updater(self, weights):\n",
    "        \"\"\"\n",
    "        Updates weights dictionary according to target_mapper.\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights : bool or dict\n",
    "            Given weights for balancing training.\n",
    "        Returns\n",
    "        -------\n",
    "        bool or dict\n",
    "            Same bool if weights are bool, updated dict otherwise.\n",
    "        \"\"\"\n",
    "        if isinstance(weights, int):\n",
    "            return weights\n",
    "        elif isinstance(weights, dict):\n",
    "            return {self.target_mapper[key]: value for key, value in weights.items()}\n",
    "        else:\n",
    "            return weights\n",
    "\n",
    "    def prepare_target(self, y):\n",
    "        return np.vectorize(self.target_mapper.get)(y)\n",
    "\n",
    "    def compute_loss(self, y_pred, y_true):\n",
    "        return self.loss_fn(y_pred, y_true.long())\n",
    "\n",
    "    def update_fit_params(\n",
    "        self,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set,\n",
    "        weights,\n",
    "    ):\n",
    "        output_dim, train_labels = infer_output_dim(y_train)\n",
    "        for X, y in eval_set:\n",
    "            check_output_dim(train_labels, y)\n",
    "        self.output_dim = output_dim\n",
    "        self._default_metric = ('auc' if self.output_dim == 2 else 'accuracy')\n",
    "        self.classes_ = train_labels\n",
    "        self.target_mapper = {\n",
    "            class_label: index for index, class_label in enumerate(self.classes_)\n",
    "        }\n",
    "        self.preds_mapper = {\n",
    "            str(index): class_label for index, class_label in enumerate(self.classes_)\n",
    "        }\n",
    "        self.updated_weights = self.weight_updater(weights)\n",
    "\n",
    "    def stack_batches(self, list_y_true, list_y_score):\n",
    "        y_true = np.hstack(list_y_true)\n",
    "        y_score = np.vstack(list_y_score)\n",
    "        y_score = softmax(y_score, axis=1)\n",
    "        return y_true, y_score\n",
    "\n",
    "    def predict_func(self, outputs):\n",
    "        outputs = np.argmax(outputs, axis=1)\n",
    "        return np.vectorize(self.preds_mapper.get)(outputs.astype(str))\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions for classification on a batch (valid)\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : a :tensor: `torch.Tensor`\n",
    "            Input data\n",
    "        Returns\n",
    "        -------\n",
    "        res : np.ndarray\n",
    "        \"\"\"\n",
    "        self.network.eval()\n",
    "\n",
    "        dataloader = DataLoader(\n",
    "            PredictDataset(X),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        results = []\n",
    "        for batch_nb, data in enumerate(dataloader):\n",
    "            data = data.to(self.device).float()\n",
    "\n",
    "            output, M_loss = self.network(data)\n",
    "            predictions = torch.nn.Softmax(dim=1)(output).cpu().detach().numpy()\n",
    "            results.append(predictions)\n",
    "        res = np.vstack(results)\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bg/n6zt_30j039_0xbq857cb_hh0000gn/T/ipykernel_9196/3837466506.py:65: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.01882 | val_0_accuracy: 0.6815  | val_0_balanced_accuracy: 0.50038 |  0:00:02s\n",
      "epoch 3  | loss: 0.56468 | val_0_accuracy: 0.774   | val_0_balanced_accuracy: 0.50386 |  0:00:07s\n",
      "epoch 6  | loss: 0.52116 | val_0_accuracy: 0.7875  | val_0_balanced_accuracy: 0.50366 |  0:00:13s\n",
      "epoch 9  | loss: 0.50632 | val_0_accuracy: 0.7865  | val_0_balanced_accuracy: 0.50128 |  0:00:19s\n",
      "epoch 12 | loss: 0.49253 | val_0_accuracy: 0.7845  | val_0_balanced_accuracy: 0.49914 |  0:00:25s\n",
      "epoch 15 | loss: 0.4748  | val_0_accuracy: 0.774   | val_0_balanced_accuracy: 0.49774 |  0:00:31s\n",
      "epoch 18 | loss: 0.44518 | val_0_accuracy: 0.7665  | val_0_balanced_accuracy: 0.49561 |  0:00:36s\n",
      "epoch 21 | loss: 0.41606 | val_0_accuracy: 0.769   | val_0_balanced_accuracy: 0.50157 |  0:00:42s\n",
      "epoch 24 | loss: 0.37024 | val_0_accuracy: 0.7305  | val_0_balanced_accuracy: 0.49992 |  0:00:48s\n",
      "epoch 27 | loss: 0.30881 | val_0_accuracy: 0.6715  | val_0_balanced_accuracy: 0.48968 |  0:00:54s\n",
      "epoch 30 | loss: 0.28111 | val_0_accuracy: 0.7095  | val_0_balanced_accuracy: 0.50848 |  0:01:00s\n",
      "epoch 33 | loss: 0.23126 | val_0_accuracy: 0.67    | val_0_balanced_accuracy: 0.51932 |  0:01:06s\n",
      "epoch 36 | loss: 0.20142 | val_0_accuracy: 0.707   | val_0_balanced_accuracy: 0.51302 |  0:01:12s\n",
      "epoch 39 | loss: 0.15246 | val_0_accuracy: 0.696   | val_0_balanced_accuracy: 0.49295 |  0:01:18s\n",
      "epoch 42 | loss: 0.13556 | val_0_accuracy: 0.6865  | val_0_balanced_accuracy: 0.50879 |  0:01:23s\n",
      "epoch 45 | loss: 0.14552 | val_0_accuracy: 0.725   | val_0_balanced_accuracy: 0.52266 |  0:01:29s\n",
      "epoch 48 | loss: 0.1068  | val_0_accuracy: 0.684   | val_0_balanced_accuracy: 0.5142  |  0:01:36s\n",
      "epoch 51 | loss: 0.08557 | val_0_accuracy: 0.7125  | val_0_balanced_accuracy: 0.5165  |  0:01:41s\n",
      "epoch 54 | loss: 0.05867 | val_0_accuracy: 0.6925  | val_0_balanced_accuracy: 0.50209 |  0:01:47s\n",
      "epoch 57 | loss: 0.07723 | val_0_accuracy: 0.682   | val_0_balanced_accuracy: 0.49982 |  0:01:53s\n",
      "epoch 60 | loss: 0.06328 | val_0_accuracy: 0.6895  | val_0_balanced_accuracy: 0.49932 |  0:01:59s\n",
      "epoch 63 | loss: 0.0514  | val_0_accuracy: 0.6785  | val_0_balanced_accuracy: 0.49323 |  0:02:05s\n",
      "epoch 66 | loss: 0.04019 | val_0_accuracy: 0.677   | val_0_balanced_accuracy: 0.49141 |  0:02:11s\n",
      "epoch 69 | loss: 0.04416 | val_0_accuracy: 0.682   | val_0_balanced_accuracy: 0.49283 |  0:02:17s\n",
      "epoch 72 | loss: 0.04073 | val_0_accuracy: 0.7     | val_0_balanced_accuracy: 0.51296 |  0:02:23s\n",
      "epoch 75 | loss: 0.0373  | val_0_accuracy: 0.71    | val_0_balanced_accuracy: 0.50705 |  0:02:28s\n",
      "epoch 78 | loss: 0.03613 | val_0_accuracy: 0.6935  | val_0_balanced_accuracy: 0.50622 |  0:02:34s\n",
      "epoch 81 | loss: 0.03095 | val_0_accuracy: 0.691   | val_0_balanced_accuracy: 0.50552 |  0:02:40s\n",
      "epoch 84 | loss: 0.02559 | val_0_accuracy: 0.6845  | val_0_balanced_accuracy: 0.49791 |  0:02:46s\n",
      "epoch 87 | loss: 0.03084 | val_0_accuracy: 0.68    | val_0_balanced_accuracy: 0.50118 |  0:02:52s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m X_train_fold, y_train_fold \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[train_idx], y_train\u001b[38;5;241m.\u001b[39miloc[train_idx]\n\u001b[1;32m     11\u001b[0m X_valid_fold, y_valid_fold \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[test_idx], y_train\u001b[38;5;241m.\u001b[39miloc[test_idx]\n\u001b[0;32m---> 13\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_fold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_fold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbalanced_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid_fold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid_fold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 230\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Call method on_epoch_begin for all callbacks\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch_idx)\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n",
      "Cell \u001b[0;32mIn[5], line 437\u001b[0m, in \u001b[0;36mTabModel._train_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_batch_begin(batch_idx)\n\u001b[0;32m--> 437\u001b[0m     batch_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_batch_end(batch_idx, batch_logs)\n\u001b[1;32m    441\u001b[0m epoch_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n",
      "Cell \u001b[0;32mIn[5], line 473\u001b[0m, in \u001b[0;36mTabModel._train_batch\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m    471\u001b[0m     param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m output, M_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(output, y)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Add the overall sparsity loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/pytorch_tabnet/tab_network.py:583\u001b[0m, in \u001b[0;36mTabNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    582\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder(x)\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtabnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/pytorch_tabnet/tab_network.py:468\u001b[0m, in \u001b[0;36mTabNetNoEmbeddings.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    467\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 468\u001b[0m     steps_output, M_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mstack(steps_output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_multi_task:\n\u001b[1;32m    472\u001b[0m         \u001b[38;5;66;03m# Result will be in list format\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/pytorch_tabnet/tab_network.py:168\u001b[0m, in \u001b[0;36mTabNetEncoder.forward\u001b[0;34m(self, x, prior)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# output\u001b[39;00m\n\u001b[1;32m    167\u001b[0m masked_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(M, x)\n\u001b[0;32m--> 168\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeat_transformers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m d \u001b[38;5;241m=\u001b[39m ReLU()(out[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_d])\n\u001b[1;32m    170\u001b[0m steps_output\u001b[38;5;241m.\u001b[39mappend(d)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/pytorch_tabnet/tab_network.py:703\u001b[0m, in \u001b[0;36mFeatTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 703\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecifics(x)\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/pytorch_tabnet/tab_network.py:746\u001b[0m, in \u001b[0;36mGLU_Block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    743\u001b[0m     layers_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_glu)\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m glu_id \u001b[38;5;129;01min\u001b[39;00m layers_left:\n\u001b[0;32m--> 746\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39madd(x, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglu_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mglu_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    747\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m scale\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/pytorch_tabnet/tab_network.py:770\u001b[0m, in \u001b[0;36mGLU_Layer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    769\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[0;32m--> 770\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    771\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(x[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim], torch\u001b[38;5;241m.\u001b[39msigmoid(x[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim :]))\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/pytorch_tabnet/tab_network.py:36\u001b[0m, in \u001b[0;36mGBN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     35\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvirtual_batch_size)), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x_) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(res, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/pytorch_tabnet/tab_network.py:36\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     35\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvirtual_batch_size)), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(res, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = TabNetClassifier(verbose=3,seed=9724)\n",
    "classifier.weight_updater(1)\n",
    "# stratified kfold\n",
    "X_train = train.drop(['Death'],axis=1).copy()\n",
    "y_train = train['Death']\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_valid_fold, y_valid_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    classifier.fit(X_train=X_train_fold.to_numpy(), y_train=y_train_fold.to_numpy().squeeze(),\n",
    "                    max_epochs=1000,\n",
    "                    patience=100,\n",
    "                    eval_metric=['accuracy', 'balanced_accuracy'],\n",
    "                    eval_set = [(X_valid_fold.to_numpy(), y_valid_fold.to_numpy().squeeze())],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
